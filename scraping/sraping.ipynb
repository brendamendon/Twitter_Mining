{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código de Scraping na busca avançada do Twitter\n",
    "\n",
    "> Desenvolvido por Brenda Mendonça.  \n",
    "> OBS: Parte do código utiliza aplicação de cookies na página de login do Twitter, extraído de um código desenvolvido por [Otávio Iasbeck](https://github.com/OIasbeck/Scrapping_Selenium/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from csv import DictWriter\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_driver(driver_type):\n",
    "    # Define qual driver será utilizado\n",
    "    if driver_type == 1:\n",
    "        driver = webdriver.Firefox()\n",
    "    elif driver_type == 2:\n",
    "        driver = webdriver.Chrome()\n",
    "    elif driver_type == 3:\n",
    "        driver = webdriver.Ie()\n",
    "    elif driver_type == 4:\n",
    "        driver = webdriver.Opera()\n",
    "    elif driver_type == 5:\n",
    "        driver = webdriver.PhantomJS()\n",
    "    \n",
    "    # Aguardando 5 segundos para continuar a execução do código\n",
    "    driver.wait = WebDriverWait(driver, 5)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abre_html(driver, page):\n",
    "    # Abre a página\n",
    "    driver.get(page)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_cookies(driver, dir):\n",
    "    try:\n",
    "        # Carrega os cookies\n",
    "        cookies = pickle.load(open(fr'{dir}\\cookies.pkl', \"rb\"))\n",
    "\n",
    "        # Deleta os cookies da página\n",
    "        driver.delete_all_cookies()\n",
    "\n",
    "        for cookie in cookies:\n",
    "            # Verifica a chave 'expiry' do cookie (que é um dicionário)\n",
    "            if isinstance(cookie.get('expiry'), float):\n",
    "                cookie['expiry'] = int(cookie['expiry']) \n",
    "\n",
    "            # Aplica o valor da chave no driver da página\n",
    "            driver.add_cookie(cookie)\n",
    "        print(\"Os cookies foram aplicados com sucesso!\")\n",
    "\n",
    "    except:\n",
    "        print(\"Houve um problema ao aplicar os cookies\")\n",
    "        raise Exception\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(nome,user,tweet_date,tweet_text,words):\n",
    "    # Abre um arquivo em modo escrita e leitura\n",
    "    with open(r\"..\\bases\\tweets_{}.csv\".format(words), \"a+\", encoding='utf-8') as csv_file:\n",
    "        # Definindo os nomes dos campos para cada coluna\n",
    "        fieldnames = ['Nome', 'Username', 'Data', 'Texto']\n",
    "\n",
    "        # Cria um dicionário com as linhas do csv\n",
    "        writer = DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Grava os dados no arquivo csv\n",
    "        writer.writerow({'Nome': nome, 'Username': user, 'Data': tweet_date, 'Texto': tweet_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(driver, start_date, end_date, words, lang, max_time, diretorio, page):\n",
    "    # Autenticação da página\n",
    "    driver = abre_html(driver, page)\n",
    "    driver = aplica_cookies(driver, dir=diretorio)\n",
    "\n",
    "    # Idiomas para filtrar os tweets\n",
    "    languages = { 1: 'en', 2: 'pt', 3: 'es', 4: 'fr', 5: 'de', 6: 'ru', 7: 'zh'}\n",
    "\n",
    "    # Construção da URL para busca avançada\n",
    "    url = \"https://twitter.com/search?q=\"\n",
    "    url += \"%24{0}%20(%24{0})\".format(words)\n",
    "    if lang != 0:\n",
    "        url += \"%20lang%3A{}\".format(languages[lang])\n",
    "    url += \"%20until%3A{0}%20since%3A{1}\".format(end_date, start_date)\n",
    "    url += \"%20-filter%3Areplies&src=typed_query\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Rolar página pelo tempo estabelecido\n",
    "    start_time = time.time()\n",
    "    while (time.time() - start_time) < max_time:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        # print('Time left: ',  str(round(max_time - (time.time() - start_time))))\n",
    "\n",
    "        try:\n",
    "            # Pegando o código html dos tweets\n",
    "            tweet_divs = driver.page_source\n",
    "            soup = BeautifulSoup(tweet_divs, \"html.parser\")\n",
    "            content = soup.find_all('article')\n",
    "\n",
    "            for c in content:\n",
    "                try:\n",
    "                    # Capturando o texto do tweet\n",
    "                    tweet_text = c.find('div', {'data-testid': 'tweetText'}).text\n",
    "                    \n",
    "                    # Capturando o nome da pessoa que fez o tweet\n",
    "                    tweet_name = c.find('div', {'data-testid': 'User-Name'}).text.strip()\n",
    "                    name_parts = tweet_name.split('@')\n",
    "                    nome = name_parts[0]\n",
    "                    user = '@' + name_parts[1].split('·')[0]\n",
    "\n",
    "                    # Capturando a data do tweet\n",
    "                    date_elem = c.find('time')\n",
    "                    tweet_date = date_elem.text.strip()\n",
    "\n",
    "                    print(f\"Nome: {nome}\")\n",
    "                    print(f\"User: {user}\")\n",
    "                    print(f\"Data: {tweet_date}\")\n",
    "                    print(f\"Tweet: {tweet_text}\")\n",
    "                    print(\"----------------------\")\n",
    "\n",
    "                    try:\n",
    "                        write_csv(nome,user,tweet_date,tweet_text,words)\n",
    "                    except:\n",
    "                        print('csv error')\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Algo de errado aconteceu!\")\n",
    "            print(e)\n",
    "            driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ''' \n",
    "        CÓDIGO PRINCIPAL \n",
    "    '''\n",
    "\n",
    "    # Chave que define o navegador\n",
    "    driver_type = 2\n",
    "\n",
    "    # Lista de strings a serem buscadas nos tweets\n",
    "    words = ['$AMZN']\n",
    "\n",
    "    # Diretório do arquivo .pkl com os cookies de autenticação de login\n",
    "    diretorio = '..\\pkl'\n",
    "\n",
    "    # Pagina inicial para autenticação\n",
    "    page = \"https://twitter.com/home\"\n",
    "\n",
    "    # Define o range de datas para a pesquisa\n",
    "    start_date = '2023-05-27'\n",
    "    end_date = '2023-06-27'\n",
    "\n",
    "    # Chave que define o idioma dos tweets\n",
    "    lang = 2\n",
    "\n",
    "    # Tempo de busca dos tweets em segundos\n",
    "    max_time = 60\n",
    "    \n",
    "    # Inicializa o navegador\n",
    "    driver = init_driver(driver_type)\n",
    "\n",
    "    # Chama a função que faz o scraping passando seus argumentos \n",
    "    scrape_tweets(driver, start_date, end_date, words, lang, max_time, diretorio, page)\n",
    "    time.sleep(5)\n",
    "    print(\"Um arquivo com os tweets foi gerado!\")\n",
    "\n",
    "    # Fecha o navegador e encerra sua instância\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "        EXECUÇÃO DO ESCOPO PRINCIPAL\n",
    "    '''\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
